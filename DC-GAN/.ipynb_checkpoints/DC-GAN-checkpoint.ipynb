{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0002\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "LATENT_DIM = 100\n",
    "IMG_SHAPE = (1,32,32) # 스트라이드 떄문에 2의 제곱\n",
    "IMG_SIZE = 32\n",
    "SAMPLE_INTERVAL = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((IMG_SHAPE[1], IMG_SHAPE[2])), transforms.ToTensor(), transforms.Normalize([0.5],[0.5])])\n",
    "train_dataset = torchvision.datasets.MNIST(\"../data\", download = True, train = True, transform = transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, drop_last = True,batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 conv_name 과 batchnorm2d 가 오면 weight 초기화 이 표현 외워두기 나중에 Module의 apply함수와 잘 어울림\n",
    "def weights_init_normal(layer):\n",
    "    layer_name = layer.__class__.__name__\n",
    "    if layer_name.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(layer.weight.data, 0.0, 0.02)\n",
    "    elif layer_name.find(\"BatchNorm2d\") != -1:\n",
    "        nn.init.normal_(layer.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(layer.bias.data, 0.0)\n",
    "        \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # conv layer로 들어가기 위한 가로세로 길이 MNIST기준으로는 원본이 32 32인데 8 8을 처음 레이어로 넣는다. 그러고 나서 업샘플 2번으로 원본 형태로 맞춤\n",
    "        self.init_size = IMG_SIZE // 4\n",
    "        self.init_linear = nn.Linear(LATENT_DIM, 128 * (self.init_size ** 2))\n",
    "        \n",
    "        self.conv_layer = []\n",
    "        # BatchNorm부터 시작하는것에 주의하자. 즉 여기에 들어가는 레이어의 채널은 128채널.\n",
    "        self.conv_layer.append(nn.BatchNorm2d(128))\n",
    "        self.conv_layer.append(nn.Upsample(scale_factor=2))\n",
    "        self.conv_layer.append(nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=1))\n",
    "        self.conv_layer.append(nn.BatchNorm2d(128,0.8))\n",
    "        self.conv_layer.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.conv_layer.append(nn.Upsample(scale_factor=2))\n",
    "        self.conv_layer.append(nn.Conv2d(128, 64, kernel_size = 3, padding = 1, stride=1))\n",
    "        self.conv_layer.append(nn.BatchNorm2d(64, 0.8))\n",
    "        self.conv_layer.append(nn.LeakyReLU(0.2, inplace = True))\n",
    "        self.conv_layer.append(nn.Conv2d(64, IMG_SHAPE[0], kernel_size=3, padding=1,stride=1))\n",
    "        self.conv_layer.append(nn.Tanh())\n",
    "        self.conv_layer = nn.Sequential(*self.conv_layer)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        latent = self.init_linear(z)\n",
    "        latent = latent.reshape(BATCH_SIZE, 128, self.init_size, self.init_size)\n",
    "        img = self.conv_layer(latent)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def block(in_channels, out_channels, bn = True):\n",
    "            block = [nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride=2, padding=1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_channels))\n",
    "            return block\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(1, 16, bn = False), # 16\n",
    "            *block(16,32),  # 8\n",
    "            *block(32,64),  # 4\n",
    "            *block(64,128)  # 2\n",
    "        )\n",
    "        \n",
    "        \n",
    "        ds_size = IMG_SHAPE[1] // (2 ** 4)\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128* (ds_size ** 2), 1), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, img):\n",
    "        output = self.model(img)\n",
    "        output_flat = output.reshape(BATCH_SIZE, -1)\n",
    "        output = self.adv_layer(output_flat)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr = LEARNING_RATE, betas=(BETA1, BETA2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr = LEARNING_RATE, betas=(BETA1, BETA2))\n",
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : [0/200], BATCH : [0/468], D loss : 0.6932916641235352, G loss 0.6879968643188477\n",
      "EPOCH : [0/200], BATCH : [100/468], D loss : 0.3869830369949341, G loss 1.155838966369629\n",
      "EPOCH : [0/200], BATCH : [200/468], D loss : 0.46658939123153687, G loss 1.175823450088501\n",
      "EPOCH : [0/200], BATCH : [300/468], D loss : 0.42679333686828613, G loss 1.24635648727417\n",
      "EPOCH : [0/200], BATCH : [400/468], D loss : 0.42900294065475464, G loss 1.2830543518066406\n",
      "EPOCH : [1/200], BATCH : [0/468], D loss : 0.46856778860092163, G loss 1.1965960264205933\n",
      "EPOCH : [1/200], BATCH : [100/468], D loss : 0.3432844877243042, G loss 1.371164321899414\n",
      "EPOCH : [1/200], BATCH : [200/468], D loss : 0.2730921506881714, G loss 1.706671118736267\n",
      "EPOCH : [1/200], BATCH : [300/468], D loss : 0.2947070002555847, G loss 2.200956344604492\n",
      "EPOCH : [1/200], BATCH : [400/468], D loss : 0.38421493768692017, G loss 1.2756949663162231\n",
      "EPOCH : [2/200], BATCH : [0/468], D loss : 0.23132628202438354, G loss 1.0368592739105225\n",
      "EPOCH : [2/200], BATCH : [100/468], D loss : 0.22343048453330994, G loss 0.9030610918998718\n",
      "EPOCH : [2/200], BATCH : [200/468], D loss : 0.28835442662239075, G loss 1.347832441329956\n",
      "EPOCH : [2/200], BATCH : [300/468], D loss : 0.2688620388507843, G loss 2.650240898132324\n",
      "EPOCH : [2/200], BATCH : [400/468], D loss : 0.24797356128692627, G loss 2.9479427337646484\n",
      "EPOCH : [3/200], BATCH : [0/468], D loss : 0.29054340720176697, G loss 1.3715636730194092\n",
      "EPOCH : [3/200], BATCH : [100/468], D loss : 0.2218455672264099, G loss 1.0753527879714966\n",
      "EPOCH : [3/200], BATCH : [200/468], D loss : 0.15988139808177948, G loss 2.788026809692383\n",
      "EPOCH : [3/200], BATCH : [300/468], D loss : 0.3079882860183716, G loss 2.5859079360961914\n",
      "EPOCH : [3/200], BATCH : [400/468], D loss : 0.22564077377319336, G loss 2.4494502544403076\n",
      "EPOCH : [4/200], BATCH : [0/468], D loss : 0.26526257395744324, G loss 2.129222869873047\n",
      "EPOCH : [4/200], BATCH : [100/468], D loss : 0.20752929151058197, G loss 0.999747633934021\n",
      "EPOCH : [4/200], BATCH : [200/468], D loss : 0.27528852224349976, G loss 1.5360181331634521\n",
      "EPOCH : [4/200], BATCH : [300/468], D loss : 0.11499660462141037, G loss 2.6841177940368652\n",
      "EPOCH : [4/200], BATCH : [400/468], D loss : 0.10973630845546722, G loss 3.4122138023376465\n",
      "EPOCH : [5/200], BATCH : [0/468], D loss : 0.10441955924034119, G loss 1.4857618808746338\n",
      "EPOCH : [5/200], BATCH : [100/468], D loss : 0.12954218685626984, G loss 2.281918525695801\n",
      "EPOCH : [5/200], BATCH : [200/468], D loss : 0.10324276983737946, G loss 2.4425768852233887\n",
      "EPOCH : [5/200], BATCH : [300/468], D loss : 0.11448092758655548, G loss 3.139103651046753\n",
      "EPOCH : [5/200], BATCH : [400/468], D loss : 0.1773768663406372, G loss 2.751254081726074\n",
      "EPOCH : [6/200], BATCH : [0/468], D loss : 0.16797074675559998, G loss 1.713442325592041\n",
      "EPOCH : [6/200], BATCH : [100/468], D loss : 0.10477276891469955, G loss 2.6302313804626465\n",
      "EPOCH : [6/200], BATCH : [200/468], D loss : 0.07808703929185867, G loss 4.541966915130615\n",
      "EPOCH : [6/200], BATCH : [300/468], D loss : 0.053954727947711945, G loss 3.535137176513672\n",
      "EPOCH : [6/200], BATCH : [400/468], D loss : 0.15006789565086365, G loss 2.5386481285095215\n",
      "EPOCH : [7/200], BATCH : [0/468], D loss : 0.07681917399168015, G loss 3.0689306259155273\n",
      "EPOCH : [7/200], BATCH : [100/468], D loss : 0.0862608551979065, G loss 0.8010857105255127\n",
      "EPOCH : [7/200], BATCH : [200/468], D loss : 0.1047128438949585, G loss 3.456989049911499\n",
      "EPOCH : [7/200], BATCH : [300/468], D loss : 0.24423111975193024, G loss 2.852982521057129\n",
      "EPOCH : [7/200], BATCH : [400/468], D loss : 0.05617118626832962, G loss 2.0619215965270996\n",
      "EPOCH : [8/200], BATCH : [0/468], D loss : 0.16058750450611115, G loss 2.1547107696533203\n",
      "EPOCH : [8/200], BATCH : [100/468], D loss : 0.20295220613479614, G loss 2.9646856784820557\n",
      "EPOCH : [8/200], BATCH : [200/468], D loss : 0.10587077587842941, G loss 2.743152141571045\n",
      "EPOCH : [8/200], BATCH : [300/468], D loss : 0.21851174533367157, G loss 4.050579071044922\n",
      "EPOCH : [8/200], BATCH : [400/468], D loss : 0.06323894113302231, G loss 3.7079505920410156\n",
      "EPOCH : [9/200], BATCH : [0/468], D loss : 0.04257519170641899, G loss 3.119135618209839\n",
      "EPOCH : [9/200], BATCH : [100/468], D loss : 0.060510117560625076, G loss 2.1568832397460938\n",
      "EPOCH : [9/200], BATCH : [200/468], D loss : 0.09014508128166199, G loss 1.98740553855896\n",
      "EPOCH : [9/200], BATCH : [300/468], D loss : 0.07159058004617691, G loss 1.9554219245910645\n",
      "EPOCH : [9/200], BATCH : [400/468], D loss : 0.060965798795223236, G loss 4.097770690917969\n",
      "EPOCH : [10/200], BATCH : [0/468], D loss : 0.4801676869392395, G loss 6.814553260803223\n",
      "EPOCH : [10/200], BATCH : [100/468], D loss : 0.05515772104263306, G loss 5.427021026611328\n",
      "EPOCH : [10/200], BATCH : [200/468], D loss : 0.16185054183006287, G loss 4.146814346313477\n",
      "EPOCH : [10/200], BATCH : [300/468], D loss : 0.031075499951839447, G loss 4.0402069091796875\n",
      "EPOCH : [10/200], BATCH : [400/468], D loss : 0.042863260954618454, G loss 3.0883028507232666\n",
      "EPOCH : [11/200], BATCH : [0/468], D loss : 0.061479344964027405, G loss 4.812602519989014\n",
      "EPOCH : [11/200], BATCH : [100/468], D loss : 0.12145292013883591, G loss 3.450688123703003\n",
      "EPOCH : [11/200], BATCH : [200/468], D loss : 0.1883881837129593, G loss 2.6029324531555176\n",
      "EPOCH : [11/200], BATCH : [300/468], D loss : 0.043530818074941635, G loss 4.842506408691406\n",
      "EPOCH : [11/200], BATCH : [400/468], D loss : 0.12500670552253723, G loss 4.054585933685303\n",
      "EPOCH : [12/200], BATCH : [0/468], D loss : 0.0207306407392025, G loss 3.024542808532715\n",
      "EPOCH : [12/200], BATCH : [100/468], D loss : 0.052275851368904114, G loss 2.4807498455047607\n",
      "EPOCH : [12/200], BATCH : [200/468], D loss : 0.07181894034147263, G loss 4.419971466064453\n",
      "EPOCH : [12/200], BATCH : [300/468], D loss : 0.05290864780545235, G loss 5.010575294494629\n",
      "EPOCH : [12/200], BATCH : [400/468], D loss : 0.03917495906352997, G loss 4.263339042663574\n",
      "EPOCH : [13/200], BATCH : [0/468], D loss : 0.02870061993598938, G loss 3.9628982543945312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-896406f6c74d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer_D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLATENT_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mfake_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "real_label = Variable(torch.ones(BATCH_SIZE, 1), requires_grad=False).to(device)\n",
    "fake_label = Variable(torch.zeros(BATCH_SIZE, 1), requires_grad=False).to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (img, _) in enumerate(train_loader):\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        z = nn.init.normal_(torch.zeros(BATCH_SIZE, LATENT_DIM)).to(device)\n",
    "        \n",
    "        fake_imgs = generator(z)\n",
    "        real_imgs = img.to(device)\n",
    "        \n",
    "        fake_preds = discriminator(fake_imgs)\n",
    "        real_preds = discriminator(real_imgs)\n",
    "        \n",
    "        dis_loss_fake = adversarial_loss(fake_preds, fake_label)\n",
    "        dis_loss_real = adversarial_loss(real_preds, real_label)\n",
    "        \n",
    "        dis_loss = (dis_loss_fake + dis_loss_real) / 2\n",
    "        dis_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        z = nn.init.normal_(torch.zeros(BATCH_SIZE, LATENT_DIM)).to(device)\n",
    "        \n",
    "        fake_imgs = generator(z)\n",
    "        fake_preds = discriminator(fake_imgs)\n",
    "        \n",
    "        gen_loss = adversarial_loss(fake_preds, real_label)\n",
    "        gen_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        if i%100==0:\n",
    "            print(\"EPOCH : [{}/{}], BATCH : [{}/{}], D loss : {}, G loss {}\".format(epoch, NUM_EPOCHS, i, len(train_loader), dis_loss, gen_loss))\n",
    "            \n",
    "    if epoch % 10==0:\n",
    "        if not os.path.isdir(\"./results\"):\n",
    "            os.makedirs(\"./results\", exist_ok = True)\n",
    "        torchvision.utils.save_image(fake_imgs[:25], \"./results/{}.png\".format(epoch), nrow=5, normalize=True)    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlawjdghek",
   "language": "python",
   "name": "rlawjdghek"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
