{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 100\n",
    "IMG_SHAPE = (1, 28,28)\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0002\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "N_CHANNELS = 1\n",
    "SAMPLE_INTERVAL = 500\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5],[0.5])\n",
    "])\n",
    "train_dataset = torchvision.datasets.MNIST(\"../data\", download = True, train = True, transform = transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def linear_block(in_channels, out_channels, bn = True):\n",
    "            layers = [nn.Linear(in_channels, out_channels)]\n",
    "            if bn:\n",
    "                layers.append(nn.BatchNorm1d(out_channels))\n",
    "                \n",
    "            layers.append(nn.LeakyReLU(0.2, inplace = True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *linear_block(LATENT_DIM, 128, bn = False),\n",
    "            *linear_block(128, 256),\n",
    "            *linear_block(256, 512),\n",
    "            *linear_block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(IMG_SHAPE))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.reshape(img.shape[0], *IMG_SHAPE) # (batch_size x channels x w x h)\n",
    "        return img\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(IMG_SHAPE)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Linear(256, 1), # output = 1이므로 sigmoid\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        img_flat = img.reshape(img.shape[0], -1)\n",
    "        output = self.model(img_flat)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# generator.to(device)\n",
    "# discriminator.to(device)\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr = LEARNING_RATE, betas = (BETA1, BETA2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr = LEARNING_RATE, betas = (BETA1, BETA2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "EPOCH : [0/200], BATCH : [0/468], G loss : 0.5355530977249146, D loss : 0.6051766872406006\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "EPOCH : [0/200], BATCH : [50/468], G loss : 0.926758885383606, D loss : 0.6098442673683167\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "EPOCH : [0/200], BATCH : [100/468], G loss : 1.1179261207580566, D loss : 0.577553391456604\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "EPOCH : [0/200], BATCH : [150/468], G loss : 0.7020896673202515, D loss : 0.5998863577842712\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n",
      "gen imgs : torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8f049da5eff8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLATENT_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mgen_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 항상 gan을 학습하기 전에 discriminator를 위한 real_label과 fake_label을 만들어 둔다. 단 정적으로\n",
    "real_label = Variable(torch.ones((BATCH_SIZE, 1)), requires_grad = False).to(device)\n",
    "fake_label = Variable(torch.zeros((BATCH_SIZE, 1)), requires_grad = False).to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        # generator train\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        z = nn.init.normal_(torch.zeros((BATCH_SIZE, LATENT_DIM))).to(device)\n",
    "        \n",
    "        gen_imgs = generator(z)\n",
    "        gen_loss = adversarial_loss(discriminator(gen_imgs), real_label) # 생성자 입장에서는 생성 이미지를 진짜처럼 여겨야 한다. \n",
    "        \n",
    "        gen_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # discriminator train\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        real_imgs = imgs.to(device)\n",
    "        real_preds = discriminator(real_imgs)\n",
    "        fake_preds = discriminator(gen_imgs.detach())\n",
    "        \n",
    "        dis_loss_real = adversarial_loss(real_preds, real_label)\n",
    "        dis_loss_fake = adversarial_loss(fake_preds, fake_label)\n",
    "        dis_loss = (dis_loss_real + dis_loss_fake) / 2\n",
    "        dis_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"EPOCH : [{}/{}], BATCH : [{}/{}], G loss : {}, D loss : {}\".format(epoch, NUM_EPOCHS, i, len(train_loader), gen_loss, dis_loss))\n",
    "        \n",
    "        \n",
    "    if epoch % 10==0:\n",
    "        if not os.path.isdir(\"./results\"):\n",
    "            os.makedirs(\"./results\", exist_ok=True)\n",
    "        torchvision.utils.save_image(gen_imgs.data[:25], \"./results/{:d}.png\".format(epoch), nrow = 5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlawjdghek",
   "language": "python",
   "name": "rlawjdghek"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
