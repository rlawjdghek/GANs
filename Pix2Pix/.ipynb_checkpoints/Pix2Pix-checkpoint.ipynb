{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "scenic-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"dark_background\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from model import *\n",
    "from utils import save_figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "female-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):  \n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout\n",
    "        self.file = None \n",
    "    \n",
    "    def open(self, file_path, mode=None):\n",
    "        if mode is None: mode = 'w'\n",
    "        self.file = open(file_path, mode)\n",
    "    \n",
    "    def write(self, message, is_terminal=1, is_file=1):\n",
    "        if \"\\r\" in message: is_file=0\n",
    "        if is_terminal:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "        if is_file:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quiet-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments & logger\n",
    "class args:\n",
    "    batch_size = 32\n",
    "    learning_rate = 2e-4\n",
    "    b1 = 0.5\n",
    "    b2 = 0.999\n",
    "    epochs = 1000\n",
    "    H = 256\n",
    "    W = 256\n",
    "    alpha = 100\n",
    "    log_dir = \"./log\"\n",
    "    log_name = \"log.txt\"\n",
    "    save_dir = \"./save_model\"\n",
    "    save_paths = [\"./{}/generator_1.pth\".format(save_dir), \"./{}/discriminator_1.pth\".format(save_dir)]\n",
    "    figure_dir = \"./gene_figure\"\n",
    "    \n",
    "class Logger(object):  \n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout\n",
    "        self.file = None \n",
    "    \n",
    "    def open(self, file_path, mode=None):\n",
    "        if mode is None: mode = 'w'\n",
    "        self.file = open(file_path, mode)\n",
    "    \n",
    "    def write(self, message, is_terminal=1, is_file=1):\n",
    "        if \"\\r\" in message: is_file=0\n",
    "        if is_terminal:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "        if is_file:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "vietnamese-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "class facades_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, mode=\"train\"):\n",
    "        self.paths = glob(os.path.join(data_dir, mode, \"*\"))\n",
    "        print(\"{} => num_imgs : {}\".format(mode, len(self.paths)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.paths[idx], cv2.IMREAD_COLOR) / 255.0\n",
    "        h, w = img.shape[:2]\n",
    "        img = np.transpose(img, (2, 0 ,1)) # [H x W x C] => [C x H x W]\n",
    "        img = (img-0.5) / 0.5  # normalization\n",
    "        sketch = img[:, :, w//2:w]\n",
    "        real = img[:, :, :w//2]\n",
    "        if np.random.random() < 0.5:  # sketch flip 하면 real 도 flip해야 하므로 이렇게 해야된다. transpose로 하면 안 맞을 수 있다. \n",
    "            real = real[:, :, ::-1].copy()\n",
    "            sketch = sketch[:, :, ::-1].copy()\n",
    "        real = torch.FloatTensor(real)\n",
    "        sketch = torch.FloatTensor(sketch)\n",
    "        return real, sketch\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pressed-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train => num_imgs : 49825\n",
      "val => num_imgs : 200\n"
     ]
    }
   ],
   "source": [
    "train_dataset = facades_dataset(\"../data/edges2shoes/edges2shoes/\", mode=\"train\")\n",
    "valid_dataset = facades_dataset(\"../data/edges2shoes/edges2shoes/\", mode=\"val\")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, drop_last=True, pin_memory=True, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=args.batch_size, drop_last=True, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "patent-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "real_label = torch.autograd.Variable(torch.ones((args.batch_size, 1, args.H // 16, args.W // 16)), requires_grad=False).to(device)\n",
    "gene_label = torch.autograd.Variable(torch.zeros((args.batch_size, 1, args.H // 16, args.W // 16)), requires_grad=False).to(device)\n",
    "\n",
    "generator = GeneratorUNet().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "if os.path.isfile(args.save_paths[0]):\n",
    "    generator.load_state_dict(torch.load(args.save_paths[0]))\n",
    "    print(\"generator load success!!!!\")\n",
    "if os.path.isfile(args.save_paths[1]) :\n",
    "    discriminator.load_state_dict(torch.load(args.save_paths[1]))\n",
    "    print(\"discriminator load success!!!!\")\n",
    "    \n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr = args.learning_rate, betas=[args.b1, args.b2])\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr = args.learning_rate, betas=[args.b1, args.b2])\n",
    "criterion_MSE = torch.nn.MSELoss()\n",
    "criterion_L1 = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accurate-dress",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      " Batch : [1556/1557] => G loss : 5.209813594818115, D loss : 0.0439424179494380954G loss : 0.003348209196701646, D loss : 2.8240629035281017e-05\n",
      "epoch : 1\n",
      " Batch : [1250/1557] => G loss : 6.4219560623168945, D loss : 0.050603397190570836"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d9e4f275fed3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"make directory : {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./save_model/generator_{}.pth\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./save_model/discriminator_{}.pth\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r Batch : [{}/{}] => G loss : {}, D loss : {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GANs\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GANs\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m             \u001b[0mbuf_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger = Logger()\n",
    "if not os.path.isdir(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "    print(\"make directory : {}\".format(args.log_dir))\n",
    "logger.open(os.path.join(args.log_dir, args.log_name))\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    print(\"epoch : {}\".format(epoch))\n",
    "    total_G_loss = torch.FloatTensor([0.])\n",
    "    total_D_loss = torch.FloatTensor([0.])   \n",
    "    \n",
    "    for i, (real, sketch) in enumerate(train_loader):\n",
    "        real_img = real_img.to(device)\n",
    "        sketch = sketch.to(device)\n",
    "        \n",
    "        gene_img = generator(sketch)\n",
    "    \n",
    "        # train discriminator\n",
    "        real_preds = discriminator(real_img, sketch)\n",
    "        gene_preds = discriminator(gene_img.detach(), sketch)\n",
    "        D_real_loss = criterion_L1(real_preds, real_label)\n",
    "        D_gene_loss = criterion_L1(gene_preds, gene_label)\n",
    "        D_loss = (D_real_loss + D_gene_loss) / 2\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # train generator\n",
    "        gene_preds = discriminator(gene_img, sketch)\n",
    "        G_pixel_loss = criterion_MSE(real_img, gene_img)\n",
    "        G_adv_loss = criterion_L1(gene_preds, real_label)\n",
    "        G_loss = G_adv_loss + args.alpha * G_pixel_loss\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        if not os.path.isdir(args.save_dir):\n",
    "            os.makedirs(args.save_dir)\n",
    "            print(\"make directory : {}\".format(args.save_dir))\n",
    "        torch.save(generator.state_dict(), \"./save_model/generator_{}.pth\".format(epoch))\n",
    "        torch.save(discriminator.state_dict(), \"./save_model/discriminator_{}.pth\".format(epoch))\n",
    "        logger.write(\"\\r Batch : [{}/{}] => G loss : {}, D loss : {}\".format(i, len(train_loader), G_loss, D_loss))\n",
    "        \n",
    "        total_G_loss += G_loss.cpu()\n",
    "        total_D_loss += D_loss.cpu()\n",
    "    print(\"G loss : {}, D loss : {}\".format(G_loss / i, D_loss / i))\n",
    "    save_figure(real_img.detach().cpu(), gene_img.detach().cpu(), sketch.detach().cpu(), args.figure_dir, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-matter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GANs",
   "language": "python",
   "name": "gans"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
